# -*- coding: utf-8 -*-
"""Main Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pWRX-xCe2aElT72JW98JYrfigHznfOqH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
import re
import nltk
nltk.download('stopwords')

data=pd.read_csv('/content/olist_customers_dataset.csv')
data.head()

geo_data=pd.read_csv('/content/olist_geolocation_dataset.csv')
geo_data

order_itemdata=pd.read_csv('/content/olist_order_items_dataset.csv')
order_itemdata

pay_data=pd.read_csv('/content/olist_order_payments_dataset.csv')
pay_data

rev_data=pd.read_csv('/content/olist_order_reviews_dataset.csv')
rev_data

orders=pd.read_csv('/content/olist_orders_dataset.csv')
orders

order_prddata=pd.read_csv('/content/olist_products_dataset.csv')
order_prddata

order_selldata=pd.read_csv('/content/olist_sellers_dataset.csv')
order_selldata

order_prd_catdata=pd.read_csv('/content/product_category_name_translation.csv')
order_prd_catdata

datasets=[data,geo_data,order_itemdata,pay_data,rev_data,orders,order_prddata,order_selldata,order_prd_catdata]
datasets

titles=["customers","geolocations","items","payments","reviews","orders","products","sellers","category_translations"]

info_df=pd.DataFrame({},)

info_df['dataset']=titles
info_df['no_of_columns']=[len(df.columns) for df in datasets]
info_df['columns_name']=[",".join(list(df.columns)) for df in datasets]
info_df['no_of_rows']=[len(df) for df in datasets]

info_df.style.background_gradient(cmap='Greys')

#checking datatypes

datasets=[data,geo_data,order_itemdata,pay_data,rev_data,orders,order_prddata,order_selldata,order_prd_catdata]
titles=["customers","geolocations","items","payments","reviews","orders","products","sellers","category_translations"]

numerics=['int16','int32','int64','float16','float32','float64']

new_df=pd.DataFrame({},)
new_df['dataset']=titles
new_df['numeric_features']=[len((df.select_dtypes(include=numerics)).columns) for df in datasets]
new_df['num_feature_name']=[','.join(list((df.select_dtypes(include=numerics)).columns)) for df in datasets]
new_df['object_features']=[len((df.select_dtypes(include=object)).columns) for df in datasets]
new_df['obj_feature_name']=[','.join(list((df.select_dtypes(include=object)).columns)) for df in datasets]
new_df['bool_features']=[len((df.select_dtypes(include=bool)).columns) for df in datasets]
new_df.style.background_gradient(cmap='Greys')

#checking no of null values

datasets=[data,geo_data,order_itemdata,pay_data,rev_data,orders,order_prddata,order_selldata,order_prd_catdata]
titles=["customers","geolocations","items","payments","reviews","orders","products","sellers","category_translations"]

info_df_n=pd.DataFrame({},)
info_df_n['dataset']=titles
#creating column of name of columns in the dataset
info_df_n['cols']=[','.join([col for col,null in df.isnull().sum().items()]) for df in datasets]
#creating total number of columns in the dataset 
info_df_n['cols_no']=[df.shape[1] for df in datasets]
#counting total null values
info_df_n['null_no']=[df.isnull().sum().sum() for df in datasets]
#creating total number of columns in the dataset with null-values 
info_df_n['null_cols_no']=[len([col for col,null in df.isnull().sum().items() if null>0]) for df in datasets]
#creating column names in the dataset with null-values 
info_df_n['null_cols']=[','.join([col for col,null in df.isnull().sum().items() if null >0 ])for df in datasets]

info_df_n.style.background_gradient(cmap='Greys')

rev_new=rev_data.drop(['review_comment_title','review_creation_date','review_id','review_answer_timestamp'],axis=1)

rev_new

df=pd.merge(orders, pay_data, on='order_id')
df=df.merge(data, on='customer_id')
df=df.merge(order_itemdata, on='order_id')
df=df.merge(order_prddata, on='product_id')
df=df.merge(order_prd_catdata, on='product_category_name')
df=df.merge(rev_new, on='order_id')
df.head()

print("No. of rows:",len(df))
print('No. of columns:',len(df.columns))

df.isnull().sum()

plt.figure(figsize=(15,10))
sns.heatmap(df.corr(),annot=True,cmap="Blues")

"""**Handling Missing Values**"""

index=(df[df['order_delivered_customer_date'].isnull()==True].index.values)
index

df['order_approved_at'].fillna(df['order_purchase_timestamp'],inplace=True)
df['order_delivered_customer_date'].fillna(df['order_estimated_delivery_date'],inplace=True)

#dropping order delivery carrier date
df.drop(labels='order_delivered_carrier_date',axis=1,inplace=True)

#checking the replaced values

df.order_estimated_delivery_date[index[0]]

df.order_delivered_customer_date[index[0]]

df.order_approved_at[index[0]]

df.order_purchase_timestamp[index[0]]

#Handling missing values of numerical features

df['product_weight_g'].fillna(df['product_weight_g'].median(),inplace=True)
df['product_length_cm'].fillna(df['product_length_cm'].median(),inplace=True)
df['product_height_cm'].fillna(df['product_height_cm'].median(),inplace=True)
df['product_width_cm'].fillna(df['product_width_cm'].median(),inplace=True)

#Handling missing values of text column

print("percentage of null reviews:",df['review_comment_message'].isnull().sum()/len(df)*100)

df['review_comment_message'].fillna('no review',inplace=True)

df.isnull().sum()

dup_rows=df[df.duplicated(['order_id','customer_id','order_purchase_timestamp','order_delivered_customer_date','customer_unique_id','review_comment_message'])]
dup_rows.head()

#Deduplication of entries

df=df.drop_duplicates(subset={'order_id','customer_id','order_purchase_timestamp','order_delivered_customer_date'},keep='first',inplace=False)
df=df.reindex()
df.head()

print("Number of rows after deduplication:",len(df))
print("Number of columns after deduplication:",len(df.columns))

df.head()

df[['order_purchase_timestamp','order_approved_at','order_delivered_customer_date','order_estimated_delivery_date']]=df[['order_purchase_timestamp','order_approved_at','order_delivered_customer_date','order_estimated_delivery_date']].apply(pd.to_datetime)

df.dtypes

df.shape

df.describe()

#checking the target variable i.e review score

df.review_score.value_counts()

df['review_score']=df['review_score'].apply([lambda x: 0 if x<3 else 1])

df['review_score'].value_counts()

y_value_counts=df['review_score'].value_counts()

print("Total positive values:",y_value_counts[1],",",(y_value_counts[1]/(y_value_counts[1]+y_value_counts[0]))*100,"%")
print("Total negative values:",y_value_counts[0],",",(y_value_counts[0]/(y_value_counts[1]+y_value_counts[0]))*100,"%")

plt.figure(figsize=(10,10))
plt.xlabel('Label')
plt.ylabel('Total Reviews')
plt.title('Positive Vs Negative Reviews')
plt.bar('0',df['review_score'].value_counts()[0],color='Grey',label='negative')
plt.bar('1',df['review_score'].value_counts()[1],color='#2e4884',label='positive')
plt.legend()

plt.figure(figsize=(10,10))
labels=['Positive','Negative']
sizes=[y_value_counts[1],y_value_counts[0]]
explode=(0,0.1)
color=('LightGreen','Red')
plt.pie(sizes,labels=labels,colors=color,explode=explode,autopct="%1.1f%%",shadow=True)
plt.title("Pie chart for review score")
plt.show()

#finding corr- values of the features with review_score

df.corr().review_score.sort_values(ascending=False)

df['seller_id']

df['customer_id']

df['product_id']

print("The number of seller_id:-",len(df.seller_id))
print("The number of unique seller_id:-",len((df.seller_id).unique()))
print("The number of customer_id:-",len(df.customer_id))
print("The number of unique customer_id:-",len((df.customer_id).unique()))
print("The number of product_id:-",len(df.product_id))
print("The number of unique product_id:-",len((df.product_id).unique()))

plt.figure(figsize=(10,10))
plt.ylabel("No. of Unique IDs")
plt.xlabel("Different Unique IDs")
plt.title("Total Unique IDs")

plt.bar('seller_id',len((df.seller_id).unique()),color='Blue',label='seller_id')
plt.bar('product_id',len((df.product_id).unique()),color='orange',label='product_id')
plt.bar('customer_id',len((df.customer_id).unique()),color='green',label='customer_id')

plt.legend()

"""**Uivariate Analysis: payment_type**"""

df['payment_type'].value_counts()

#Bar Plot

plt.figure(figsize=(10,10))
plt.xlabel("Payment Type")
plt.ylabel("Total")
plt.title("Total payment type")
x=['credit_card','boleto','voucher','debit_card']
y=[73251,19203,2578,1484]
color=['Blue','orange','red','green']
plt.bar(x,y,color=color)
plt.legend()

#Pie Chart

plt.figure(figsize=(10,10))
labels=['credit_card','boleto','voucher','debit_card']
sizes=[73251,19203,2578,1484]
color=['Blue','orange','red','green']
explode=(0,0.1,0.1,0.1)
plt.pie(sizes,labels=labels,colors=color,explode=explode,autopct='%0.1f%%',shadow=True)
plt.show()

temp=pd.DataFrame(df.groupby('payment_type')['review_score'].agg(lambda x:x.eq(1).sum())).reset_index()
temp

temp['total']=list(pd.DataFrame(df.groupby('payment_type')['review_score'].agg([('total','count'),('avg','mean')]))['total'])
temp['avg']=list(pd.DataFrame(df.groupby('payment_type')['review_score'].agg([('total','count'),('avg','mean')]))['avg'])
temp.sort_values(by=['total'],ascending=True)

def pareto_plot(df,x=None,y=None,title=None,show_pct_y=False, pct_format='{0:.0%}'):
  xlabel=x
  ylabel=y
  tmp=df.sort_values(y,ascending=False)
  x=tmp[x].values
  y=tmp[y].values
  weights=y/y.sum()
  cumsum=weights.cumsum()

  fig,ax1=plt.subplots(figsize=(10,10))
  ax1.bar(x,y,color='Blue')
  ax1.set_xlabel(xlabel)
  ax1.set_ylabel(ylabel)

  ax2=ax1.twinx()
  ax2.plot(x, cumsum, '-ro')
  ax2.set_ylabel('',color='r')
  ax2.tick_params('y',colors='r')

  vals=ax2.get_yticks()
  ax2.set_yticklabels(['{:,.2%}'.format(x) for x in vals])

  if not show_pct_y:
    ax2.set_yticks([])

  formatted_weights=[pct_format.format(x) for x in cumsum]
  for i, txt in enumerate(formatted_weights):
    ax2.annotate(txt, (x[i],cumsum[i]),fontsize=15)
  
  if title:
    plt.title(title,color='dimgrey',fontsize=15)
  
  plt.tight_layout()
  plt.show()

pareto_plot(temp,x='payment_type',y='total',title='Pareto Plot of counts of each payment type')

#Let us see how this categorical feature related with our target variable

plt.figure(figsize=(10,10))
p1=plt.barh(temp.payment_type,temp.total,color='grey')
p2=plt.barh(temp.payment_type,temp.review_score,color='#2e4884')
plt.title('Payment types and user accounts',color='dimgrey',fontsize=15)
plt.ylabel('Payment types',fontsize=14)
plt.xlabel('Total',fontsize=14)
plt.legend((p1[0],p2[0]), ('total_reviews','positive review by users'))
plt.show()

"""**Univariate Analysis: Customer count based on State wise**

"""

plt.figure(figsize=(10,10))
ax=df.customer_state.value_counts().sort_values(ascending=False).plot(kind='bar',color='grey')
ax.set_title("Top 15 consumer states of Brazil",fontsize=15)
ax.set_xlabel("States")
ax.set_ylabel("No. of consumers")
plt.legend()
plt.show()

def stack_plot(data,xtick,col2,col3='total'):
  ind=np.arange(data.shape[0])

  plt.figure(figsize=(10,10))
  p1=plt.bar(ind,data[col3].values,color='grey')
  p2=plt.bar(ind,data[col2].values,color='#2e4884')

  plt.ylabel('Reviews')
  plt.title('% of review score')
  plt.xticks(ind-0.1, list(data[xtick].values))
  plt.legend((p1[0],p2[1]),('total_reviews','positive_review'))
  plt.show()

# Count number of zeros in dataframe python

temp_1=pd.DataFrame(df.groupby('customer_state')['review_score'].agg(lambda x:x.eq(1).sum()).reset_index())
temp_1

temp_1['total']=list(pd.DataFrame(df.groupby('customer_state')['review_score'].agg([('total','count'),('avg','mean')]))['total'])
temp_1['avg']=list(pd.DataFrame(df.groupby('customer_state')['review_score'].agg([('total','count'),('avg','mean')]))['avg'])
temp_1=temp_1.rename(columns={'review_score':'positive_review'})
temp_1=temp_1.sort_values(by=['total'],ascending=False)
temp_1

stack_plot(temp_1,'customer_state',col2='positive_review',col3='total')

"""**Univariate Analysis: product_category_name_english**

"""

plt.figure(figsize=(10,10))
ax=df.product_category_name_english.value_counts().sort_values(ascending=False)[0:15].plot(kind="bar",color="grey")
ax.set_title("Top selling product categories")
ax.set_xlabel("States")
ax.set_ylabel("No. of orders")
plt.show()

temp_2=pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg(lambda x:x.eq(1).sum()).reset_index())
temp_2['total']=list(pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg([('total','count'),('avg','mean')]))['total'])
temp_2['avg']=list(pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg([('total','count'),('avg','mean')]))['avg'])
temp_2.sort_values(by=['total'],ascending=True)

plt.figure(figsize=(22,18))
plt.barh(temp_2.product_category_name_english,temp_2.total,color='grey')
plt.barh(temp_2.product_category_name_english,temp_2.review_score,color='Blue')
plt.title("Top selling product categories in Brazilian E-Commerce (2016-2018)",fontsize=15)
plt.xlabel("Total",fontsize=14)
plt.ylabel("product_category_name_english",fontsize=14)
plt.show()

"""**Uivarite Analysis:frequency of orders Vs Number of Consumers**"""

plt.figure(figsize=(10,6))
num_orders=df['customer_unique_id'].value_counts().value_counts()/df.shape[0]*100
num_orders=num_orders.reset_index()

num_orders.rename(columns={'index':'no. of orders','customer_unique_id':'log percentage of customers'},inplace=True)

sns.barplot(data=num_orders,x='no. of orders',y='log percentage of customers',palette='Dark2_r')
plt.yscale('log')
plt.title('No. of orders per customers',color='dimgrey')

"""**Univariate Analysis: Order_status**"""

plt.figure(figsize=(10,6))
total=float(len(df))
ax=sns.countplot(data=df,x='order_status',palette='gist_rainbow')
ax.set_title('Order Status',color='dimgrey')
for p in ax.patches:
  percentage='{:.1f}%'.format(100*p.get_height()/total)
  x=p.get_x()+p.get_width()
  y=p.get_height()
  ax.annotate(percentage,(x,y),ha='center')
plt.show()

plt.figure(figsize=(10,5))
total=float(len(df))
ax=sns.countplot(data=df,x='order_status',hue='review_score')
ax.set_title('Order status with % of reviews',color='dimgrey')
for p in ax.patches:
  percentage='{:.1f}%'.format(100*p.get_height()/total)
  x=p.get_x()+p.get_width()
  y=p.get_height()
  ax.annotate(percentage,(x,y),ha='center')
plt.show()

"""**Univariate Analysis on different Timestamps**"""

#calculating number of days for the data is taken

print(df.order_approved_at.max() - df.order_approved_at.min(), 'from',
      df.order_approved_at.min(), 'to' ,df.order_approved_at.max())

# Extracting attributes for purchase date - Year and Month

df['order_purchase_year']=df['order_purchase_timestamp'].apply(lambda x:x.year) #gives year
df['order_purchase_month']=df['order_purchase_timestamp'].apply(lambda x:x.month) #gives month
df['order_purchase_month_name']=df['order_purchase_timestamp'].apply(lambda x:x.strftime('%b')) #gives month in short form
df['order_purchase_year_month']=df['order_purchase_timestamp'].apply(lambda x:x.strftime('%Y%m')) #gives month and year
df['order_purchase_date']=df['order_purchase_timestamp'].apply(lambda x:x.strftime('%Y%m%d')) #gives month, year and date
df['order_purchase_month_yr']=df['order_purchase_timestamp'].apply(lambda x:x.strftime('%b-%Y')) 

# Extracting attributes for purchase date - Day and Day of Week
df['order_purchase_day']=df['order_purchase_timestamp'].apply(lambda x:x.day)
df['order_purchase_dayofweek']=df['order_purchase_timestamp'].apply(lambda x:x.dayofweek)
df['order_purchase_dayofweek_name']=df['order_purchase_timestamp'].apply(lambda x:x.strftime('%a'))


# Extracting attributes for purchase date - Hour and Time of the Day
df['order_purchase_hour']=df['order_purchase_timestamp'].apply(lambda x:x.hour)
hours_bins=[-0.1,6,12,18,23]
hours_labels=['Dawn','Morning','Afternoon','Night']
df['order_purchase_time_day']=pd.cut(df['order_purchase_hour'],hours_bins,labels=hours_labels)

# New DataFrame after transformations
df.head()

sns.set_style('whitegrid')
plt.figure(figsize=(10,6))
sns.lineplot(data=df['order_purchase_year_month'].value_counts().sort_index(),color='black')
plt.title('Evolution of Total Orders in Brazilian E-Commerce',size=14)
plt.xticks(rotation=90)
plt.show()

df_month=pd.DataFrame()
df_month['date'],df_month['review_score']=list(df.order_approved_at),list(df.review_score)
df_month=df_month.dropna()
df_month=df_month.sort_values(by=['date'])
df_month

plt.figure(figsize=(10,5))
df_month['monthcount']=list(df_month.date.apply(lambda x:x.strftime('%b-%Y')))
g=sns.countplot(data=df_month, x=df_month.monthcount,palette='Greens')
g.set_xlabel('Months-Year')
g.set_ylabel('Orders count')
g.set_title('Number of orders per month-year')
g.set_xticklabels(g.get_xticklabels(),rotation=90)
plt.show()

#plotting number of positive and negative reviews per month-year

plt.figure(figsize=(15,10))
g=sns.countplot(data=df_month, x=df_month.monthcount, hue='review_score',palette=['grey','#425a90'])
total=float(len(df_month))
g.set_xlabel('Months-Year')
g.set_ylabel('Order count')
g.set_title('number of positive and negative reviews per month-year',size=14,color='Blue')
g.set_xticklabels(g.get_xticklabels(),rotation=90)
for p in g.patches:
  percentage='{:.1f}%'.format(100*p.get_height()/total)
  x=p.get_x() + p.get_width()
  y=p.get_height()
  g.annotate(percentage,(x,y),ha='center')
plt.show()

total=float(len(df))

plt.figure(figsize=(12,6))
ax1=sns.countplot(data=df, x='order_purchase_month_name',hue='review_score',palette=['grey','blue'])
ax1.set_xticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct','Nov','Dec'])
ax1.set_title('Total Reviews by Month',size=15,color='dimgrey')
for p in ax1.patches:
  percentage='{:.1f}%'.format(100*p.get_height()/total)
  x=p.get_x() + p.get_width()
  y=p.get_height()
  ax1.annotate(percentage,(x,y),ha='center')
plt.show()

plt.figure(figsize=(6,3))
ax2=sns.countplot(data=df, x='order_purchase_time_day',palette=['grey','blue'],hue='review_score')
ax2.set_title('Total Reviews by Time of the Day',size=15,color='dimgrey')
for p in ax2.patches:
  percentage='{:.1f}%'.format(100*p.get_height()/total)
  x=p.get_x() + p.get_width()
  y=p.get_height()
  ax2.annotate(percentage,(x,y),ha='center')
plt.show()

plt.figure(figsize=(8,4))
ax3=sns.countplot(data=df, x='order_purchase_dayofweek',hue='review_score',palette=['grey','blue'])
ax3.set_xticklabels(['Mon','Tue','Wed','Thurs','Fri','Sat','Sun'])
ax3.set_title('Total Reviews by Day of Week',size=15,color='dimgrey')

for p in ax3.patches:
  percentage='{:.1f}%'.format(100*(p.get_height()/total))
  x=p.get_x()+p.get_width()
  y=p.get_height()
  ax3.annotate(percentage,(x,y),ha='center')
plt.show()

df['day_to_delivery']=((df['order_delivered_customer_date']-df['order_purchase_timestamp']).dt.days)

df_dev=pd.DataFrame()
df_dev['day_to_delivery'],df_dev['review_score']=list(df.day_to_delivery),list(df.review_score)
df_dev.dropna()

plt.figure(figsize=(15,10))
plt.title("Order Counts Based on Total delivery Time(in Days)",color='dimgrey',size=15)
g=sns.countplot(data=df_dev, x='day_to_delivery',palette='copper')
g.set_xticklabels(g.get_xticklabels(),rotation=90)
g.set_xlabel('Total Days')
g.set_ylabel('Orders count')
plt.show()

"""**Univariate Analysis on Numerical Features**"""

plt.figure(figsize=(15,10))
sns.set_style('whitegrid')
ax=sns.FacetGrid(df, hue='review_score',height=5,aspect=2,palette=['#425a90','blue'])
ax.map(sns.distplot, 'price').add_legend()
plt.title('Distribution of product price per class',size=15,color='dimgrey')
plt.show()

plt.figure()
sns.set_style('whitegrid')
ax=sns.FacetGrid(df, hue='review_score', height=5, aspect=2, palette=['#2e4884','red'])
ax.map(sns.distplot,'freight_value').add_legend()
plt.title('Distribution of freight_value per class',size=15,color='dimgrey')
plt.show()

plt.figure()
sns.set_style('whitegrid')
ax=sns.FacetGrid(df,hue='review_score',height=5,aspect=2,palette=['#2e4884','orange'])
ax.map(sns.distplot,'product_height_cm').add_legend()
plt.title('Distribution of product height per class',size=15,color='dimgrey')
plt.show()

plt.figure()
sns.set_style('whitegrid')
ax=sns.FacetGrid(df, hue='review_score',height=5,aspect=2, palette=['#2e4884','yellow'])
ax.map(sns.distplot,'product_weight_g').add_legend()
plt.title('Distribution of product weight per class',size=15,color='dimgrey')
plt.show()

plt.figure()
ax=sns.FacetGrid(df,hue='review_score',height=5,aspect=2,palette=['#2e4884','brown'])
ax.map(sns.distplot, 'payment_value').add_legend()
plt.title('Distribution of payment value per class',size=15,color='dimgrey')
plt.show()

"""**Box Plot**"""

plt.figure(figsize=(14,6))
box_plot_data=[df.product_length_cm,df.product_height_cm,df.product_width_cm]
plt.boxplot(box_plot_data,labels=['product_length_cm','product_height_cm','product_width_cm'],vert=False)
plt.title("Box Plots of Product Dimensions")
plt.show()

plt.figure(figsize=(10,5))
box_plot_data=[df.payment_value,df.price]
plt.boxplot(box_plot_data,labels=['payment_value','price'],vert=False)
plt.title('Box Plots of Different Prices')
plt.show()

"""**Bivariate Analysis**"""

# Distribution of price vs freight_value per class

plt.figure(figsize=(10,10))
sns.set_style('whitegrid')
sns.scatterplot(x='price',y='freight_value',data=df,palette=['yellow','#2e4884'],hue='review_score')
plt.title('Distribution of price vs freight_value per class')
plt.show()

# Distribution of price vs product_weight_g per class

plt.figure(figsize=(10,8))
sns.set_style('whitegrid')
ax=sns.scatterplot(x='price',y='product_weight_g',hue='review_score',data=df,palette=['#2e8448','dimgrey'])
plt.title('Distribution of price vs product weight per class')
plt.show()

sns.set(style='ticks',color_codes=True)
sns.pairplot(df[['product_photos_qty','product_name_lenght','product_description_lenght','review_score']],hue='review_score',palette=['#234884','pink'])

"""**Multivariate Analysis**"""

df_mm=df[['order_purchase_month_name','price']].groupby('order_purchase_month_name').sum()
df_mm

pi=list(df_mm['price'])
li=list(df_mm.index)
res={li[i]:pi[i] for i in range(len(li))}
res

from collections import OrderedDict
months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
weeks=['Mon','Tue','Wed','Thurs','Fri','Sat','Sun']
res=dict(OrderedDict(sorted(res.items(),key=lambda x: months.index(x[0]))))
print(res)

temp_3=pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()

temp_3['total']=list(pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg([('total','count'),('avg','mean')]))['total'])
temp_3['avg']=list(pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg([('total','count'),('avg','mean')]))['avg'])

temp_3.sort_values(by=['total'],ascending=True)

rem={list(temp_3.order_purchase_month_name)[i]:list(temp_3.total)[i] for i in range(len(temp_3))}
rem=dict(OrderedDict(sorted(rem.items(),key=lambda x:months.index(x[0]))))
print(rem)

fig,ax1=plt.subplots()

color='grey'
ax1.set_xlabel('Month')
ax1.set_ylabel('Price',color=color)
ax1.plot(list(res.keys()),list(res.values()),color=color)
ax1.plot(list(res.keys()),list(res.values()),'C0o',alpha=0.5,color='grey',)
ax1.tick_params(axis= 'y',labelcolor=color)

ax2=ax1.twinx()

color='#2e4884'
ax2.set_ylabel('orders',color=color)
ax2.plot(list(res.keys()),list(rem.values()),color=color)
ax2.plot(list(res.keys()),list(rem.values()),'C0o',alpha=0.5,color='#2e4884')
ax2.tick_params(axis='y',labelcolor=color)

fig.tight_layout()
plt.show()

"""datadatadf[dfdf**Text Analysis**"""

review_df=pd.read_csv('/content/olist_order_reviews_dataset.csv')
review_df.head()

review_df.isnull().sum()

review_df.shape

review_data_title=review_df['review_comment_title']
review_data=review_df.drop('review_comment_title',axis=1)

review_data

#Dropping NAN values

review_data_title=review_data_title.dropna()
review_data=review_data.dropna()

review_data_title.shape

review_data_title.isnull().sum()

review_data.shape

review_data.isnull().sum()

# Resetting the reviews index and visualizing the data

review_data=review_data.reset_index(drop=True)
review_data.head()

review_data.shape

import nltk
nltk.download('punkt')

from nltk.corpus import stopwords

comments=[]

stop_words=set(stopwords.words('portuguese'))

for words in review_data['review_comment_message']:
  only_letters=re.sub('[^a-zA-Z]','',words)
  tokens=nltk.word_tokenize(only_letters)
  lower_case=[l.lower() for l in tokens]
  filtered_result=list(filter(lambda l:l not in stop_words,lower_case))
  comments.append(''.join(filtered_result))

comments

from wordcloud import WordCloud

#Using wordcloud to visualize the comments
unique_strings=(" ").join(comments)
wordcloud=WordCloud(width=2000,height=1000,background_color='white').generate(unique_strings)
plt.figure(figsize=(15,10))
plt.imshow(wordcloud,interpolation='bilinear')
plt.axis('off')
plt.show()

#further checking by Counting the words

from collections import Counter
words=(" ".join(review_data['review_comment_message'])).lower().split()
counts=Counter(words)

print('Most frequent words')
sorted(counts.items(),key=lambda x:x[1],reverse=True)[:15]

print('Least frequent words')
sorted(counts.items(),key=lambda x:x[1],reverse=False)[:15]

!pip install googletrans==3.1.0a0

!pip install langdetect

#  google translate(from portuguese to english)


from langdetect import detect
from googletrans import Translator

def detect_and_translate(text,target_lang):

  result_lang=detect(text)

  if result_lang==target_lang:
    return text

  else:
    translator=Translator()
    translate_text=translator.translate(text, src=result_lang, dest=target_lang)
    return translate_text

sentence="o,e,produto,a"
print(detect_and_translate(sentence,target_lang='en'))

sentence="Pode-se pagar com cartão de crédito?"
print(detect_and_translate(sentence,target_lang='hi'))

# Getting the number of words by splitting them by a space

plt.figure(figsize=(10,10))
df['words_per_review']=df.review_comment_message.apply(lambda x:len(x.split(" ")))
df['words_per_review'].hist(bins=50)
plt.xlabel('Reviews Length')
plt.ylabel('Frequency')
plt.show()

data.head()

"""**`RFM -Analysis`**

What is RFM?

Behavioral segmentation by 3 important features:

Recency — number of days since the last purchase

Frequency — number of transactions made over a given period

Monetary — amount spent over a given period of time
"""

from datetime import datetime

present=datetime(2022,11,24)
rfm=df.groupby('customer_unique_id').agg({'order_purchase_timestamp':lambda date :(present-date.max()).days,
                                          'order_id': lambda num: len(num),
                                          'payment_value':lambda price: price.sum()})

rfm.columns=['recency','frequency','monetary']
rfm['recency']=rfm['recency'].astype(int)
rfm['frequency']=rfm['frequency'].astype(int)
rfm['monetary']=rfm['monetary'].astype(float)

rfm.head()

# Plot RFM distributions

plt.figure(figsize=(10,10))

#plot distribution of R
plt.subplot(3,1,1);sns.distplot(rfm['recency'],color='black')

#plot distribution of F
plt.subplot(3,1,2);sns.distplot(rfm['frequency'],color='black')

#plot distribution of M
plt.subplot(3,1,3);sns.distplot(rfm['monetary'],color='black')

plt.show()

def partition(x):
  if x<10:
    return 1
  elif 10<=x<=35:
    return 2
  elif 35<=x<=50:
    return 3
  elif 50<=x<=75:
    return 4

rfm['f_quartile']=rfm['frequency'].map(lambda cw:partition(cw))
rfm.f_quartile.value_counts()

r_labels=range(4,0,-1); m_labels=range(1,5)

rfm['r_quartile']=pd.qcut(rfm['recency'],4,r_labels)
rfm['m_quartile']=pd.qcut(rfm['monetary'],4,m_labels)

rfm['rfm_score']=rfm.r_quartile.astype(str)+rfm.f_quartile.astype(str)+rfm.m_quartile.astype(str)
rfm.head()

rfm_count_unique=rfm.groupby('rfm_score')['rfm_score'].nunique()
rfm_count_unique.sum()

rfm['rfm_score_s']=rfm[['r_quartile','f_quartile','m_quartile']].sum(axis=1)
rfm['rfm_score_s'].head()

# Define rfm_level function

def rfm_level(df):
  if df['rfm_score_s']>=9:
    return "Cant loose them"
  elif ((df['rfm_score_s']>=8) and (df['rfm_score_s']<9)):
    return "Champions"
  elif ((df['rfm_score_s']>=7) and (df['rfm_score_s']<8)):
    return "Loyal"
  elif ((df['rfm_score_s']>=6) and (df['rfm_score_s']<7)):
    return "Potential"
  elif ((df['rfm_score_s']>=5) and (df['rfm_score_s']<6)):
    return "Promising"
  elif ((df['rfm_score_s']>=4) and (df['rfm_score_s']<5)):
    return "Needs Attention"
  else:
    return "Require Activation"

rfm['RFM_level']=rfm.apply(rfm_level,axis=1)

rfm.head()

# Calculate average values for each RFM_Level, and return a size of each segment 

rfm_level_agg=rfm.groupby('RFM_level').agg({
    'recency':'mean',
    'frequency':'mean',
    'monetary':['mean','count']
}).round(1)

print(rfm_level_agg)
rfm_level_agg.columns=rfm_level_agg.columns.droplevel()

!pip install squarify

import squarify

plt.figure(figsize=(15,10))
rfm_level_agg.columns=['RecencyMean','FrequencyMean','MonetaryMean','Count']

squarify.plot(sizes=rfm_level_agg['Count'],
              label=['Cant loose them ',
                      'Champions','Loyal','Potential','Promising','Needs Attention','Require Activation'],color=['green','blue','yellow','pink','skyblue','orange','red'])
plt.title('RFM Segments',fontsize=18,color='black')
plt.axis('off')
plt.show()

rfm.head()

rfm.to_pickle('rfm.pkl')
df.to_pickle('final.pkl')

data=pd.read_pickle('final.pkl')
data.head()

"""**Preprocessing Review Text**"""

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
nltk.download('rslp')

stopwords_pt=stopwords.words('portuguese')
print('Total portuguese words:',len(stopwords_pt))
print('Few portuguese words:',stopwords_pt[0:20])

stopwords_pt.remove('não')

stopwords_pt.remove('nem')

data['review_comment_message'].head(5)

from nltk.stem import RSLPStemmer
from tqdm import tqdm

def preprocess_text(texts):
  hyperlinks='http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+' #check for hyperlinks
  dates='([0-2][0-9]|(3)[0-1])(\/|\.)(((0)[0-9])|((1)[0-2]))(\/|\.)\d{2,4}' #check for dates
  currency_symbols='[R]{0,1}\$[ ]{0,}\d+(,|\.)\d+' #check for currency symbols
  preprocessed_text=[]
  stemmer=RSLPStemmer()  #portuguese nltk stemmer
  
  for sent in tqdm(texts):
    sent=re.sub(r"[\n\t\-\\\/]"," ",sent) #removing new lines, tabs
    sent=re.sub(hyperlinks,'url',sent) #replacing hyperlinks with url
    sent=re.sub(dates," ",sent) #removing dates
    sent=re.sub(currency_symbols,'dinheiro',sent) #replacing currency_symbols with 'dinheiro'
    sent=re.sub('[0-9]+','numero',sent) #removing digits
    sent=re.sub('([nN][ãÃaA][oO]|[ñÑ]| [nN] )',' negação ',sent) #replacing no. with negative
    sent=re.sub('\W','',sent) #removing extra white spaces
    sent=re.sub('\s+','',sent) #removing extra spaces
    sent=''.join(e for e in sent.split() if e.lower() not in stopwords_pt) #removing stopwords
    sent=''.join(stemmer.stem(e.lower()) for e in sent.split()) #stemming the stopwords
    preprocessed_text.append(sent.lower().strip())

  return preprocessed_text

processed_text=preprocess_text(data['review_comment_message'].values)

data['review_comment_message']=processed_text
data['review_comment_message'].head(5)

col= ['order_id',
 'customer_id',
 'order_purchase_timestamp',
 'order_approved_at',
 'order_delivered_customer_date',
 'order_estimated_delivery_date',
  'customer_unique_id',
 'order_item_id',
 'product_id',
 'seller_id',
 'shipping_limit_date',
 'order_purchase_month_name',
 'order_purchase_year_month',
 'order_purchase_date',
 'order_purchase_month_yr',
 'order_purchase_day',
 'order_purchase_dayofweek',
 'order_purchase_dayofweek_name',
 'order_purchase_hour',
 'order_purchase_time_day','customer_city','customer_zip_code_prefix','product_category_name']

data.drop(columns=col, axis=1, inplace=True)

data.head()

"""**Splitting data into Train and Test: Stratified Sampling**"""

x=data.drop(['review_score'],axis=1)
y=data['review_score']
print("      x  ","     y   ")
print(x.shape, y.shape)
print('\n')
x.head(1)

#train test split

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,stratify=y,random_state=25)

print("  x_train  "," y_train  ")
print(x_train.shape, y_train.shape)
print("-"*25)
print("  x_test  ","  y_test  ")
print(x_test.shape,y_test.shape)

"""**Encoding Categorical Features**

**Encoding Categorical Features: order_status**
"""

from sklearn.feature_extraction.text import CountVectorizer

vect_os_tr=CountVectorizer(binary=True)
vect_os_tr.fit(x_train['order_status'].values)

# we use the fitted CountVectorizer to convert the text to vector

os_st_tr=vect_os_tr.transform(x_train['order_status'].values)
os_st_te=vect_os_tr.transform(x_test['order_status'].values)

name_os=vect_os_tr.get_feature_names()

print('After Vectorization')
print(os_st_tr.shape, y_train.shape)
print(os_st_tr.shape, y_test.shape)
print(name_os)

"""**Encoding Categorical Features: payment_type**"""

vect_pay_tr=CountVectorizer(binary=True)
vect_pay_tr.fit(x_train['payment_type'].values)

pay_typ_tr=vect_pay_tr.transform(x_train['payment_type'].values)
pay_typ_te=vect_pay_tr.transform(x_test['payment_type'].values)

name_typ=vect_pay_tr.get_feature_names()

print('After Vectorization')
print(pay_typ_tr.shape, y_train.shape)
print(pay_typ_tr.shape, y_test.shape)
print(name_typ)

"""**Encoding Categorical Features:product_category_name_english**




"""

vectorizer=CountVectorizer()
vectorizer.fit(x_train['product_category_name_english'].values)

prod_cat_tr=vectorizer.transform(x_train['product_category_name_english'].values)
prod_cat_te=vectorizer.transform(x_test['product_category_name_english'].values)

name_prod=vectorizer.get_feature_names()

print('After Vectorization')
print(prod_cat_tr.shape,y_train.shape)
print(prod_cat_tr.shape,y_test.shape)
print(name_prod)

"""**Encoding Categorical Features: customer_state**

"""

vertorizer=CountVectorizer(binary=True)
vertorizer.fit(x_train['customer_state'].values)

state_tr=vertorizer.transform(x_train['customer_state'].values)
state_te=vertorizer.transform(x_test['customer_state'].values)

name_st=vertorizer.get_feature_names()

print('After Vectorization')
print(state_tr.shape, y_train.shape)
print(state_tr.shape,y_test.shape)
print(name_st)

"""**Featurization of text data**

"""

!pip install fastText

import fasttext.util
fasttext.util.download_model('pt',if_exists='ignore')

from gensim.models import FastText
ft_model=FastText.load_fasttext_format('/content/cc.pt.300.bin')

ft_model.wv['melhor'].shape

ft_model.similar_by_vector('produt')

def tfidfWord2Vector(text,ft_words,tfdif_words,tf_values):
  tfidf_w2v_vectors=[]
  for sentence in tqdm(text):
    vector=np.zeros(300)
    tf_idf_weight=0
    for word in sentence.split():
      if (word in ft_words) and (word in tfdif_words):
        vec=ft_model.wv[word]
        tf_idf=tf_values[word]*(sentence.count(word)/len(sentence.split()))
        vector=vector+(vec*tf_idf)
        tf_idf_weight=tf_idf_weight+tf_idf

    if tf_idf_weight!=0:
        vector=vector/tf_idf_weight
    tfidf_w2v_vectors.append(vector)
  
  tfidf_w2v_vectors=np.array(tfidf_w2v_vectors)

  return tfidf_w2v_vectors

# encoding review comment message using Tfidf weighted W2V
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf=TfidfVectorizer()
tfidf.fit(x_train['review_comment_message'])

tf_values=dict(zip(tfidf.get_feature_names(),list(tfidf.idf_)))
tfidf_words=set(tfidf.get_feature_names())
ft_words=list(ft_model.wv.vocab.keys())

tfidf_w2v_vectors_train=tfidfWord2Vector(x_train['review_comment_message'].values,ft_words,tfidf_words,tf_values)
tfidf_w2v_vectors_test=tfidfWord2Vector(x_test['review_comment_message'].values,ft_words,tfidf_words,tf_values)

import pickle 
pickle.dump(tfidf_w2v_vectors_train,open('tfidf_w2v_vectors_train_1.pkl','wb'))
pickle.dump(tfidf_w2v_vectors_test,open('tfidf_w2v_vectors_test_1.pkl','wb'))

tfidf_w2v_vectors_train=pickle.load(open('tfidf_w2v_vectors_train_1.pkl','rb'))
tfidf_w2v_vectors_test=pickle.load(open('tfidf_w2v_vectors_test_1.pkl','rb'))

"""**Numerical_features**

"""

from sklearn.preprocessing import Normalizer

def normalizer(col):
  normalizer=Normalizer()
  normalizer.fit(x_train[col].values.reshape(-1,1))
  x_train_norm=normalizer.transform(x_train[col].values.reshape(-1,1))
  x_test_norm=normalizer.transform(x_test[col].values.reshape(-1,1))
  return x_train_norm,x_test_norm

#numerical features
num=['payment_sequential',
 'payment_installments',
 'payment_value',
 'price',
 'freight_value',
 'product_name_lenght',
 'product_description_lenght',
 'product_photos_qty',
 'product_weight_g',
 'product_length_cm',
 'product_height_cm',
 'product_width_cm',
 'day_to_delivery']

tr=[]
te=[]
for i in num:
  a,b=normalizer(i)
  tr.append(a)
  te.append(b)

from scipy.sparse import hstack, csr_matrix
import numpy as np

x_tr_num=np.hstack((tr))
x_te_num=np.hstack((te))

print('Final Data Matrix')
print(x_tr_num.shape,y_train.shape)
print(x_te_num.shape,y_test.shape)

from scipy.sparse import hstack

x_tr=hstack((tfidf_w2v_vectors_train,os_st_tr,pay_typ_tr,prod_cat_tr,state_tr,x_tr_num)).tocsr()
x_te=hstack((tfidf_w2v_vectors_test,os_st_te,pay_typ_te,prod_cat_te,state_te,x_te_num)).tocsr()

print('Final Data Matrix')
print(x_tr.shape, y_train.shape)
print(x_te.shape,y_test.shape)

"""**Random Model**

"""

from sklearn.metrics import confusion_matrix

def confusion_metrices_plot(y_real,y_pred,y_test,y_test_pred,name):
  cmap=sns.light_palette("#425a90",as_cmap=True)
  cmap_=sns.light_palette("#000000", as_cmap=True)
  c1=confusion_matrix(y_real,y_pred)
  c2=confusion_matrix(y_test,y_test_pred)

  fig,ax=plt.subplots(1,2,figsize=(15,5))
  ax1=sns.heatmap(c1,cmap=cmap,annot=True,fmt=".2f",ax=ax[0])
  ax1.set_xlabel('Predicted Class')
  ax1.set_ylabel('Original Class')
  ax1.set_title('Train Confusion Matrix')

  ax2=sns.heatmap(c2,cmap=cmap_,annot=True,fmt=".2f",ax=ax[1])
  ax2.set_xlabel('Predicted Class')
  ax2.set_ylabel('Orgiginal Class')
  ax2.set_title('Test Confusion Matrix')

  plt.show()

import random
from sklearn.metrics import f1_score
train_data_len=x_tr.shape[0]
test_data_len=x_te.shape[0]

y_train_pred=np.zeros((train_data_len,1))
for i in range(train_data_len):
  rand_c=random.randint(0,1)
  y_train_pred[i]=(rand_c)
print('Train F1 Score:',f1_score(y_train,y_train_pred,average='macro'))
y_test_pred=np.zeros((test_data_len,1))
for i in range(test_data_len):
  rand_c=random.randint(0,1)
  y_test_pred[i]=(rand_c)
print('Test F1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'bs_rn.png')

"""**Naive Bayes Model**

"""

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()

scaler.fit(x_tr.todense())
x_tr=scaler.transform(x_tr.todense())

scaler.fit(x_te.todense())
x_te=scaler.transform(x_te.todense())

# Training Logistic regression model and chekcing f1 score metric

from sklearn.naive_bayes import MultinomialNB
alpha=[10**x for x in range(-5,4)]
train_scores=[]
test_scores=[]

for i in alpha:
  nb_cfl=MultinomialNB(alpha=i,fit_prior=False)
  nb_cfl.fit(x_tr,y_train)
  train_sc=f1_score(y_train,nb_cfl.predict(x_tr),average='macro')
  test_sc=f1_score(y_test,nb_cfl.predict(x_te),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print('Alpha:',i,'Train Score:',train_sc,'Test Score',test_sc)

plt.plot(np.log(alpha),train_scores,label='Train Score',color='black')
plt.plot(np.log(alpha),test_scores,label='Test Score',alpha=0.5,color='blue')
plt.xlabel('Alpha')
plt.ylabel('Score')
plt.grid()
plt.title('Alpha Vs Score')

from sklearn.model_selection import RandomizedSearchCV
clf=MultinomialNB(class_prior=np.array([0.5,0.5]),fit_prior=False)
params={'alpha':[10**x for x in range(-5,4)]}

nb_cfl=RandomizedSearchCV(clf,param_distributions=params,n_jobs=-1,verbose=10,scoring='f1_macro',random_state=25,return_train_score=True)
nb_cfl.fit(x_tr,y_train)
print('mean train scores:',nb_cfl.cv_results_['mean_train_score'])
print('mean test scores:',nb_cfl.cv_results_['mean_test_score'])

print("Best Parameters:",nb_cfl.best_params_)
print("Best Score:",nb_cfl.best_score_)

from sklearn.metrics import roc_curve, auc

clf=MultinomialNB(alpha=10,class_prior=np.array([0.5,0.5]),fit_prior=False)
clf.fit(x_tr,y_train)

y_train_pred=clf.predict(x_tr)
y_test_pred=clf.predict(x_te)

print("Train f1 score:",f1_score(y_train,y_train_pred,average='macro'))
print("Test f1 score:",f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'bs_nb.png')

"""**Logistic regression**"""

from sklearn.linear_model import SGDClassifier
alpha=[10**x for x in range(-5,4)]
train_scores=[]
test_scores=[]

for i in alpha:
  lr=SGDClassifier(loss='log',penalty='l2',alpha=i,n_jobs=-1,random_state=25)
  lr.fit(x_tr,y_train)
  train_sc=f1_score(y_train,lr.predict(x_tr),average='macro')
  test_sc=f1_score(y_test,lr.predict(x_te),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print("Alpha:",i,"Train Score",train_sc,"Test Score:",test_sc)

plt.plot(np.log(alpha),train_scores,label="Train Score",color="black")
plt.plot(np.log(alpha),test_scores,label="Test Score",color="blue")
plt.xlabel("Alpha")
plt.ylabel("Score")
plt.grid()
plt.title("Alpha Vs Score")

sgd=SGDClassifier(loss='log',n_jobs=-1,random_state=25)
params={'alpha':[10**x for x in range(-5,4)]}

random_cfl1=RandomizedSearchCV(sgd,param_distributions=params,verbose=10,n_jobs=-1,random_state=25,return_train_score=True)
random_cfl1.fit(x_tr,y_train)

print('Mean Train Score:',random_cfl1.cv_results_['mean_train_score'])
print('Mean Test Score:',random_cfl1.cv_results_['mean_test_score'])

print("Best parameters:",random_cfl1.best_params_)
print("Best Score:",random_cfl1.best_score_)

sgd=SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1,random_state=25)
sgd.fit(x_tr,y_train)

y_train_pred=sgd.predict(x_tr)
y_test_pred=sgd.predict(x_te)

print("Train f1 Score:",f1_score(y_train,y_train_pred,average='macro'))
print("Test f1 Score:",f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'bs_lr.png')

data_n=pd.read_pickle('final.pkl')
data_n.head()

data_n.columns

#sellers count for each product

fea_1=data_n.groupby('product_id').count()['seller_id']
fea_1_df=pd.DataFrame()
fea_1_df['product_id']=fea_1.index
fea_1_df['sellers_count']=fea_1.values
fea_1_df.head()

#sellers count for each product

fea_2=data_n.groupby('order_id').count()['product_id']
fea_2_df=pd.DataFrame()
fea_2_df['order_id']=fea_2.index
fea_2_df['products_count']=fea_2.values
fea_2_df.head()

# Adding the seller count and products count feature to the final data set

data_n=pd.merge(data_n,fea_1_df,on='product_id')
data_n=pd.merge(data_n,fea_2_df,on='order_id')

data_n

# calculating estimated delivery time

data_n['estimated_delivery_t']=(data_n['order_estimated_delivery_date']-data_n['order_approved_at']).dt.days

# calculating actual delivery time
data_n['actual_delivery_t']=(data_n['order_delivered_customer_date']-data_n['order_approved_at']).dt.days

# calculating diff_in_delivery_time
data_n['diff_in_delivery_t']=data_n['order_estimated_delivery_date']-data_n['order_delivered_customer_date']

data_n['on_time_delivery']=data_n['order_delivered_customer_date']<data_n['order_estimated_delivery_date']
data_n['on_time_delivery']=data_n['on_time_delivery'].astype('int')

# calculating mean product value
data_n['avg_prdt_value']=data_n['price']/data_n['products_count']

# finding total order cost
data_n['total_order_cost']=data_n['price']+data_n['freight_value']

# calculating order freight ratio
data_n['order_freight_ratio']=data_n['freight_value']/data_n['price']

# finding the day of week on which order was made
data_n['purchase_dayofweek']=pd.to_datetime(data_n['order_purchase_timestamp']).dt.dayofweek

# adding is_reviewed where 1 is if review comment is given otherwise 0.

data_n['is_reviewed']=(data_n['review_comment_message']!='no_review').astype('int')

rfm=pd.read_pickle('rfm.pkl')
rfm.head()

data_n=data_n.merge(rfm,on='customer_unique_id',how='left')
data_n.head()

# Delivery estimated time and actual delivery time

plt.figure(figsize=(10,4))

plt.title('Delivery time in days')
plt.xlim(-10,200)
plt.grid()

ax1=sns.kdeplot(data_n['actual_delivery_t'],color='blue',label='Delivery Time')
ax2=sns.kdeplot(data_n['estimated_delivery_t'],color='orange',label='Estimated Delivery Time')

col= ['order_id',
 'customer_id',
 'order_purchase_timestamp',
 'order_approved_at',
 'order_delivered_customer_date',
 'order_estimated_delivery_date',
  'customer_unique_id',
 'order_item_id',
 'product_id',
 'seller_id',
 'shipping_limit_date',
  'order_purchase_year',
 'order_purchase_month',
 'order_purchase_month_name',
 'order_purchase_year_month',
 'order_purchase_date',
 'order_purchase_month_yr',
 'order_purchase_day',
 'order_purchase_dayofweek',
 'order_purchase_dayofweek_name',
 'order_purchase_hour',
 'order_purchase_time_day',
  'f_quartile',
 'r_quartile',
 'm_quartile',
 'rfm_score',
 'rfm_score_s',
 'product_category_name']

data_n.drop(columns=col,axis=1,inplace=True)
data_n.head()

#text processing

processed_text=preprocess_text(data_n['review_comment_message'].values)

data_n['review_comment_message']=processed_text
data_n['review_comment_message'].head()

#Spliting data in Train and Test.

x=data_n.drop('review_score',axis=1)
y=data_n['review_score']

print("  x   ","   y   ")
print(x.shape,y.shape)

x.head(1)

# train test split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,stratify=y,random_state=25)

print("  x_train  ","  y_train  ")
print(x_train.shape,y_train.shape)
print("="*20)
print("  x_test  ","  y_test  ")
print(x_test.shape,y_test.shape)

pickle.dump(x_train,open('x_train.pkl','wb'))
pickle.dump(x_test,open('x_test.pkl','wb'))
pickle.dump(y_train,open('y_train.pkl','wb'))
pickle.dump(y_test,open('y_test.pkl','wb'))

x_train=pickle.load(open('x_train.pkl','rb'))
x_test=pickle.load(open('x_test.pkl','rb'))
y_train=pickle.load(open('y_train.pkl','rb'))
y_test=pickle.load(open('y_test.pkl','rb'))

"""**Featurization of text data**"""

tfidf=TfidfVectorizer()
tfidf.fit(x_train['review_comment_message'])

tf_values=dict(zip(tfidf.get_feature_names(),list(tfidf.idf_)))
tfidf_words=set(tfidf.get_feature_names())
glove_words=list(ft_model.wv.vocab.keys())

tfidf_w2v_vectors_train=tfidfWord2Vector(x_train['review_comment_message'].values,glove_words,tfidf_words,tf_values)
tfidf_w2v_vectors_test=tfidfWord2Vector(x_test['review_comment_message'].values,glove_words,tfidf_words,tf_values)

tfidf_w2v_vectors_train.shape,tfidf_w2v_vectors_test.shape

pickle.dump(tfidf_w2v_vectors_train,open('tfidf_w2v_vectors_train.pkl','wb'))
pickle.dump(tfidf_w2v_vectors_test,open('tfidf_w2v_vectors_test.pkl','wb'))

"""**Encoding Categorical Features**


*Encoding Categorical Features: order_status*
"""

vectorizer=CountVectorizer(binary=True)
vectorizer.fit(x_train['order_status'].values)

order_st_tr=vectorizer.transform(x_train['order_status'].values)
order_st_te=vectorizer.transform(x_test['order_status'].values)

print('After Vectorization')
print(order_st_tr.shape,y_train.shape)
print(order_st_tr.shape,y_test.shape)

"""*Encoding Categorical Features:payment_type*"""

vectorizer=CountVectorizer(binary=True)
vectorizer.fit(x_train['payment_type'].values)

pay_typ_tr=vectorizer.transform(x_train['payment_type'].values)
pay_typ_te=vectorizer.transform(x_test['payment_type'].values)

print('After Vectorization')
print(pay_typ_tr.shape,y_train.shape)
print(pay_typ_tr.shape,y_test.shape)

"""*EncodingCategoricalFeatures:product_category_name_english*"""

vectorizer=CountVectorizer(binary=True)
vectorizer.fit(x_train['product_category_name_english'].values)

prod_cat_tr=vectorizer.transform(x_train['product_category_name_english'].values)
prod_cat_te=vectorizer.transform(x_test['product_category_name_english'].values)

print('After Vectorization')
print(prod_cat_tr.shape,y_train.shape)
print(prod_cat_te.shape,y_test.shape)

"""*Encoding Categorical Features: customer_state*"""

vectorizer=CountVectorizer(binary=True)
vectorizer.fit(x_train['customer_state'].values)

state_tr=vectorizer.transform(x_train['customer_state'].values)
state_te=vectorizer.transform(x_test['customer_state'].values)

print('After Vectorization')
print(state_tr.shape,y_train.shape)
print(state_te.shape,y_test.shape)

"""*Encoding Categorical Features: RFM_Level*"""

vectorizer=CountVectorizer(binary=True)
vectorizer.fit(x_train['RFM_level'].values)

rfm_tr=vectorizer.transform(x_train['RFM_level'].values)
rfm_te=vectorizer.transform(x_test['RFM_level'].values)

print('After Vectorization')
print(rfm_tr.shape,y_train.shape)
print(rfm_te.shape,y_test.shape)

"""## Numerical features"""

num=['payment_sequential',
 'payment_installments',
 'payment_value',
 'customer_zip_code_prefix',
 'price',
 'freight_value',
 'product_name_lenght',
 'product_description_lenght',
 'product_photos_qty',
 'product_weight_g',
 'product_length_cm',
 'product_height_cm',
 'product_width_cm',
 'day_to_delivery',
 'recency',
 'frequency',
 'monetary',
 'sellers_count',
 'products_count',
 'estimated_delivery_t',
 'actual_delivery_t',
 'diff_in_delivery_t',
 'on_time_delivery',
 'avg_prdt_value',
 'total_order_cost',
 'order_freight_ratio',
 'purchase_dayofweek',
 'is_reviewed','words_per_review']

tr=[]
te=[]

for i in num:
  a,b=normalizer(i)
  tr.append(a)
  te.append(b)

from scipy.sparse import hstack,csr_matrix
import numpy as np

x_tr_num=np.hstack((tr))
x_te_num=np.hstack((te))

print('Final Data Matrix')
print(x_tr_num.shape,y_train.shape)
print(x_te_num.shape,y_test.shape)

from scipy.sparse import hstack

x_tr=hstack((tfidf_w2v_vectors_train,order_st_tr,pay_typ_tr,prod_cat_tr,state_tr,rfm_tr,x_tr_num)).tocsr()
x_te=hstack((tfidf_w2v_vectors_test,order_st_te,pay_typ_te,prod_cat_te,state_te,rfm_te,x_te_num)).tocsr()

print("Final Data Matrix")
print(x_tr.shape, y_train.shape)
print(x_te.shape, y_test.shape)

pickle.dump(x_tr,open('x_tr.pkl','wb'))
pickle.dump(x_te,open('x_te.pkl','wb'))

x_tr=pickle.load(open('x_tr.pkl','rb'))
x_te=pickle.load(open('x_te.pkl','rb'))

# Training Logistic regression model and chekcing f1 score metric

alpha=[10**x for x in range(-5,4)]
train_scores=[]
test_scores=[]

for i in alpha:
  lr=SGDClassifier(loss='log',penalty='l2',alpha=i,n_jobs=-1,random_state=25)
  lr.fit(x_tr,y_train)
  train_sc=f1_score(y_train,lr.predict(x_tr),average='macro')
  test_sc=f1_score(y_test,lr.predict(x_te),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print('Alpha:',i,'Train Score:',train_sc,'Test Score:',test_sc)

plt.plot(np.log(alpha),train_scores,label='Train Score',color='green')
plt.plot(np.log(alpha),test_scores,label='Test Score',color='orange',alpha=0.7)
plt.xlabel('Alpha')
plt.ylabel('Score')
plt.grid()
plt.title('Alpha Vs Score')

sgd=SGDClassifier(loss='log',n_jobs=-1,random_state=25)
params={'alpha':[10**x for x in range(-5,4)]}

random_cfl1=RandomizedSearchCV(sgd,param_distributions=params,verbose=10,scoring='f1_macro',n_jobs=-1,random_state=25,return_train_score=True)
random_cfl1.fit(x_tr,y_train)

print('mean train scores:',random_cfl1.cv_results_['mean_train_score'])
print('mean test scores:',random_cfl1.cv_results_['mean_test_score'])

print("Best Parameters:",random_cfl1.best_params_)
print("Best Score:",random_cfl1.best_score_)

sgd=SGDClassifier(loss='log',alpha=0.0001,n_jobs=-1,random_state=25)
sgd.fit(x_tr,y_train)

print('Train F1 Score:',f1_score(y_train,sgd.predict(x_tr),average='macro'))
print('Test F1 Score:',f1_score(y_test,sgd.predict(x_te),average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'feat_md_lr.png')

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import load_model

# AutoEncoder Model Preparation
n_inputs=x_tr.shape[1]

# define encoder
input_data_shape=Input(shape=(n_inputs,))

#encoder layer 1
encoder=Dense(round(float(n_inputs)/2.0))(input_data_shape)
encoder=BatchNormalization()(encoder)
encoder=LeakyReLU()(encoder)

#encoder layer 2
encoder=Dense(round(float(n_inputs)/3.0))(encoder)
encoder=BatchNormalization()(encoder)
encoder=LeakyReLU()(encoder)

#bottleneck
n_bottleneck=round(float(n_inputs)/4.0)
bottleneck=Dense(n_bottleneck)(encoder)

#Decoder layer 1
decoder=Dense(round(float(n_inputs)/3.0))(bottleneck)
decoder=BatchNormalization()(decoder)
decoder=LeakyReLU()(decoder)

#Decoder layer 2
decoder=Dense(round(float(n_inputs)/2.0))(decoder)
decoder=BatchNormalization()(decoder)
decoder=LeakyReLU()(decoder)

output=Dense(n_inputs,activation='linear')(decoder)
model=Model(inputs=input_data_shape,outputs=output)
model.compile(optimizer='adam',loss='mse')

model.summary()

from keras.utils.vis_utils import plot_model
plot_model(model,to_file='encode.png',show_shapes=True,show_layer_names=True)

x_tr=x_tr.toarray()

type(x_tr)

x_te=x_te.toarray()

type(x_te)

history=model.fit(x_tr,y_train,epochs=50,batch_size=16,verbose=2,validation_data=(x_te,y_test))

plt.plot(history.history['loss'],color='black')
plt.plot(history.history['val_loss'],color='blue',alpha=0.7)
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Train','Val'])
plt.grid()
plt.show()

encoder=Model(inputs=input_data_shape,outputs=bottleneck)
encoder.save('encoder.h5')

encoder=load_model('encoder.h5')
x_train_encode=encoder.predict(x_tr)
print('x_train_encode:',x_train_encode.shape)
x_test_encode=encoder.predict(x_te)
print('x_test_encode:',x_test_encode.shape)

alpha=[10**x for x in range(-5,4)]
train_scores=[]
test_scores=[]

for i in alpha:
  lr=SGDClassifier(loss='log',penalty='l2',alpha=i,n_jobs=-1,random_state=25)
  lr.fit(x_train_encode,y_train)
  train_sc=f1_score(y_train,lr.predict(x_train_encode),average='macro')
  test_sc=f1_score(y_test,lr.predict(x_test_encode),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print('Alpha:',i,'Train Score:',train_sc, 'Test Score:',test_sc)
 
plt.plot(np.log(alpha),train_scores,label='Train Score',color='black')
plt.plot(np.log(alpha),test_scores,label='Test Score',color='blue',alpha=0.7)
plt.xlabel('Alpha')
plt.ylabel('Score')
plt.title('Alpha Vs Score')
plt.grid()

sgd=SGDClassifier(loss='log',n_jobs=-1,random_state=25)
params={'alpha':[10**x for x in range(-5,4)]}
random_cfl1=RandomizedSearchCV(sgd,param_distributions=params,verbose=10,scoring='f1_macro',n_jobs=-1,random_state=25,return_train_score=True)
random_cfl1.fit(x_train_encode,y_train)

print('mean train scores:',random_cfl1.cv_results_['mean_train_score'])
print('mean test scores:',random_cfl1.cv_results_['mean_test_score'])

print('Best Parameters:',random_cfl1.best_params_)
print('Best Score:',random_cfl1.best_score_)

sgd=SGDClassifier(loss='log',alpha=10,n_jobs=-1,random_state=25)
sgd.fit(x_train_encode,y_train)

y_train_pred=sgd.predict(x_train_encode)
y_test_pred=sgd.predict(x_test_encode)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'encoder.png')

import warnings
warnings.filterwarnings('ignore')
from tqdm import tqdm
import shutil
import os
import numpy as np
import pandas as pd
from datetime import datetime
import matplotlib
from scipy.stats import randint as sp_randint
from scipy.stats import uniform
from scipy.sparse import hstack
from wordcloud import WordCloud

x_train=pickle.load(open('x_train.pkl','rb'))
x_test=pickle.load(open('x_test.pkl','rb'))

x_train.head()

x_tr=pickle.load(open('x_tr.pkl','rb'))
x_te=pickle.load(open('x_te.pkl','rb'))
y_train=pickle.load(open('y_train.pkl','rb'))
y_test=pickle.load(open('y_test.pkl','rb'))

encoder=load_model('encoder.h5')

x_train_encode=encoder.predict(x_tr)
print('x train encode:',x_train_encode.shape)

x_test_encode=encoder.predict(x_te)
print('x test encoder:',x_test_encode.shape)

def confusion_metrices_plot(y_real,y_pred,y_test,y_test_pred,name):
  cmap_=sns.light_palette('black',as_cmap=True)
  cmap=sns.light_palette('blue',as_cmap=True)
  c1=confusion_matrix(y_real,y_pred)
  c2=confusion_matrix(y_test,y_test_pred)

  fig,ax=plt.subplots(1,2,figsize=(15,5))
  ax1=sns.heatmap(c1,cmap=cmap_,annot=True,fmt='.2f',ax=ax[0])
  ax1.set_xlabel('Predicted Class')
  ax1.set_ylabel('Original Class')
  ax1.set_title('Train Confusion Matrix')

  ax2=sns.heatmap(c2,cmap=cmap,annot=True,fmt='.2f',ax=ax[1])
  ax2.set_xlabel('Predicted Class')
  ax2.set_ylabel('Original Class')
  ax2.set_title('Test Confusion Matrix')
  plt.show()

"""**Linear SVM Model**"""

alpha=[10**x for x in range(-5,4)]
train_scores=[]
test_scores=[]

for i in alpha:
  lr=SGDClassifier(loss='hinge',penalty='l2',alpha=i,n_jobs=-1,random_state=25)
  lr.fit(x_train_encode,y_train)
  train_sc=f1_score(y_train,lr.predict(x_train_encode),average='macro')
  test_sc=f1_score(y_test,lr.predict(x_test_encode),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print('Alpha:',i,'Train Score:',train_sc,'Test Score:',test_sc)

plt.plot(np.log(alpha),train_scores,label='Train Score',color='black')
plt.plot(np.log(alpha),test_scores,label='Test Score',color='red',alpha=0.7)
plt.xlabel('Alpha')
plt.ylabel('Score')
plt.grid()
plt.title('Alpha Vs Score')

sgd=SGDClassifier(loss='hinge',n_jobs=-1,random_state=25)

params={'alpha':[10**x for x in range(-5,4)]}

random_cfl1=RandomizedSearchCV(sgd,param_distributions=params,verbose=10,scoring='f1_macro',n_jobs=-1,random_state=25,return_train_score=True)
random_cfl1.fit(x_train_encode,y_train)

print('Mean Train Score:',random_cfl1.cv_results_['mean_train_score'])
print('Mean Test Score:',random_cfl1.cv_results_['mean_test_score'])

print('Best Parameters:',random_cfl1.best_params_)
print('Best Score:',random_cfl1.best_score_)

sgd=SGDClassifier(loss='hinge',alpha=10,n_jobs=-1,random_state=25)
sgd.fit(x_train_encode,y_train)

y_train_pred=sgd.predict(x_train_encode)
y_test_pred=sgd.predict(x_test_encode)

print('Train F1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test F1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'svm.png')

"""**Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

depth=[3,10,50,100,250,500]
train_scores=[]
test_scores=[]

for i in depth:
  clf=DecisionTreeClassifier(max_depth=i,random_state=25)
  clf.fit(x_train_encode,y_train)
  train_sc=f1_score(y_train,clf.predict(x_train_encode),average='macro')
  test_sc=f1_score(y_test,clf.predict(x_test_encode),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print('Depth',i,'Train Score',train_sc,'Test Score',test_sc)

plt.plot(depth,train_scores,label='Train Score',color='black')
plt.plot(depth,test_scores,label='Test Score',color='red',alpha=0.7)
plt.xlabel('Depth')
plt.ylabel('Score')
plt.grid()
plt.title('Depth Vs Score')

from scipy.stats import randint as sp_randint

dt=DecisionTreeClassifier(random_state=25)
params={'max_depth':sp_randint(3,500),'min_samples_split':sp_randint(50,200),'min_samples_leaf':sp_randint(2,50)}

random_cfl1=RandomizedSearchCV(dt,param_distributions=params,verbose=10,scoring='f1_macro',n_jobs=-1,random_state=25,return_train_score=True)
random_cfl1.fit(x_train_encode,y_train)

print('Mean Train Score:',random_cfl1.cv_results_['mean_train_score'])
print('Mean Test Score:',random_cfl1.cv_results_['mean_test_score'])

print('Best Parameters:',random_cfl1.best_params_)
print('Best Score:',random_cfl1.best_score_)

dt=DecisionTreeClassifier(max_depth=135,min_samples_leaf=28,min_samples_split=193)
dt.fit(x_train_encode,y_train)

y_train_pred=dt.predict(x_train_encode)
y_test_pred=dt.predict(x_test_encode)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'dt.png')

"""**RandomForest Classifier**"""

from sklearn.ensemble import RandomForestClassifier
estimators=[5,10,50,100,250,500]
train_scores=[]
test_scores=[]

for i in estimators:
  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0,min_samples_leaf=52, min_samples_split=120,
            min_weight_fraction_leaf=0.0, n_estimators=i, n_jobs=-1,random_state=25,verbose=0,warm_start=False)
  clf.fit(x_train_encode,y_train)
  train_sc=f1_score(y_train,clf.predict(x_train_encode),average='macro')
  test_sc=f1_score(y_test,clf.predict(x_test_encode),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print('Estimators:',i,'Train Score',train_sc,'Test score:',test_sc)

plt.plot(estimators,train_scores,label='Train Score',color='blue')
plt.plot(estimators,test_scores,label='Test Score',color='black',alpha=0.7)
plt.xlabel('Estimators')
plt.ylabel('Score')
plt.title('Estimators Vs Score')
plt.grid()

depths=[3,9,11,15,20,35,50,70,130]
train_scores=[]
test_scores=[]

for i in depths:
  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=i, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0,min_samples_leaf=52, min_samples_split=120,
            min_weight_fraction_leaf=0.0, n_estimators=115, n_jobs=-1,random_state=25,verbose=0,warm_start=False)
  clf.fit(x_train_encode,y_train)
  train_sc=f1_score(y_train,clf.predict(x_train_encode),average='macro')
  test_sc=f1_score(y_test,clf.predict(x_test_encode),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)
  print('Depth=',i,'Train Score=',train_sc,'Test Score=',test_sc)

plt.plot(depths,train_scores,label='Train Score',color='black')
plt.plot(depths,test_scores,label='Test Score',color='orange',alpha=0.7)
plt.xlabel('Depth')
plt.ylabel('Score')
plt.title('Depth Vs Score')
plt.grid()
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import f1_score
from scipy.stats import randint as sp_randint
from scipy.stats import uniform

clf=RandomForestClassifier(random_state=25,n_jobs=-1)

params={"n_estimators":sp_randint(105,125),
        "max_depth": sp_randint(10,15),
        "min_samples_split": sp_randint(110,190),
        "min_samples_leaf": sp_randint(25,65)}

rf_random=RandomizedSearchCV(clf,param_distributions=params,verbose=10,scoring='f1_macro',n_jobs=-1,random_state=25,return_train_score=True)
rf_random.fit(x_train_encode,y_train)

print('Mean train scores:',rf_random.cv_results_['mean_train_score'])
print('Mean test scores:',rf_random.cv_results_['mean_test_score'])

print('Best Parameters:',rf_random.best_params_)
print('Best Score:',rf_random.best_score_)

rf_classifier=RandomForestClassifier(max_depth=13,min_samples_leaf=49,min_samples_split=165,n_estimators=108)
rf_classifier.fit(x_train_encode,y_train)

y_train_pred=rf_classifier.predict(x_train_encode)
y_test_pred=rf_classifier.predict(x_test_encode)

print('Train f1 score=',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score=',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'rf.png')

"""**LGBM**


"""

!pip install lightgbm

from lightgbm import LGBMClassifier
estimators=[1,3,5,10,50,100,250,500,1000]
train_scores=[]
test_scores=[]

for i in estimators:
  clf=LGBMClassifier(n_estimators=i,n_jobs=-1,random_state=25)
  clf.fit(x_train_encode,y_train)
  train_sc=f1_score(y_train,clf.predict(x_train_encode),average='macro')
  test_sc=f1_score(y_test,clf.predict(x_test_encode),average='macro')
  train_scores.append(train_sc)
  test_scores.append(test_sc)

plt.plot(estimators,train_scores,label='Train Score',color='black')
plt.plot(estimators,test_scores,label='Test Score',color='blue',alpha=0.7)
plt.plot('Estimators')
plt.plot('Score')
plt.plot('Estimator Vs Score')
plt.grid()

x_cfl=LGBMClassifier(n_jobs=-1,random_state=25)

params={'learning_rate':[0.001,0.01,0.03,0.05,0.1,0.15,0.2],
        'n_estimators':[1,3,5,10,50,100,250,500,1000],
        'max_depth':[3,5,10,15,20,50],
        'colsample_bytree':[0.1,0.3,0.5,1],
        'subsample':[0.1,0.3,0.5,1]}

random_cfl1=RandomizedSearchCV(x_cfl,param_distributions=params,verbose=10,scoring='f1_macro',n_jobs=-1,random_state=25,return_train_score=True)
random_cfl1.fit(x_train_encode,y_train)

print('Mean Train score:',random_cfl1.cv_results_['mean_train_score'])
print('Mean Test score:',random_cfl1.cv_results_['mean_test_score'])

print('Best Parameters:',random_cfl1.best_params_)
print('Best Score:',random_cfl1.best_score_)

lgbm=LGBMClassifier(subsample=0.5,n_estimators=250,max_depth=3,learning_rate=0.03,colsample_bytree=0.3)
lgbm.fit(x_train_encode,y_train)

y_train_pred=lgbm.predict(x_train_encode)
y_test_pred=lgbm.predict(x_test_encode)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'lgbm.png')

"""**5. XGB Classifier**"""

from xgboost import XGBClassifier
import random
from scipy.stats import randint as sp_randint
clf=XGBClassifier()
params={"n_estimators":sp_randint(105,125),
        "eta":[round(random.uniform(0.1, 1.0 ), 1) for i in range(0,20)]}

xg_random=RandomizedSearchCV(clf,param_distributions=params,scoring='f1_macro',n_iter=5,cv=3,n_jobs=-1,random_state=25,return_train_score=True)
xg_random.fit(x_train_encode,y_train)

print('Mean Train score:',xg_random.cv_results_['mean_train_score'])
print('Mean Test score:',xg_random.cv_results_['mean_test_score'])

print(xg_random.best_estimator_)

clf=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, eta=0.1, gamma=0,
              learning_rate=0.1, max_delta_step=0, max_depth=3,
              min_child_weight=1, missing=None, n_estimators=108, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)

clf.fit(x_tr,y_train)
y_train_pred=clf.predict(x_tr)
y_test_pred=clf.predict(x_te)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'xgboost.png')

"""**6. Adaboost Model**"""

from sklearn.ensemble import AdaBoostClassifier
x_cfl=AdaBoostClassifier(random_state=25)
params={'learning_rate':[0.001,0.01,0.03,0.05,0.1,0.15,0.2],
       'n_estimators':[1,3,5,10,50,100,250,500,1000]}

random_cfl1=RandomizedSearchCV(x_cfl,param_distributions=params,verbose=10,n_jobs=-1,random_state=25,scoring='f1_macro')
random_cfl1.fit(x_train_encode,y_train)

print('Mean Train score:',f1_score(y_train,random_cfl1.predict(x_train_encode),average='macro'))
print('Mean Test score:',f1_score(y_test,random_cfl1.predict(x_test_encode),average='macro'))

print('Best parameters:',random_cfl1.best_params_)
print('Best Score:',random_cfl1.best_score_)

ada=AdaBoostClassifier(n_estimators=1,learning_rate= 0.001,random_state=25)
ada.fit(x_train_encode,y_train)

y_train_pred=ada.predict(x_train_encode)
y_test_pred=ada.predict(x_test_encode)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'ada.png')

"""### 8.**StackingClassifier**"""

# defining the base models
est0=list()
est0.append(('lr',SGDClassifier(loss='log',alpha=0.1,n_jobs=-1,random_state=25)))
est0.append(('svm', SGDClassifier(loss='hinge',alpha=1,n_jobs=-1,random_state=25)))
est0.append(('dt', DecisionTreeClassifier(max_depth=135,min_samples_leaf=28,min_samples_split=193,random_state=25)))
est0.append(('rf', RandomForestClassifier(max_depth=13,min_samples_leaf=49,min_samples_split=165,n_estimators=108,random_state=25,n_jobs=-1)))
est0.append(('xgb', XGBClassifier(n_estimators=123,max_depth=3,subsample=1,learning_rate=0.1,colsample_bytree=1,n_jobs=-1,random_state=25)))

est_final=SGDClassifier(loss='log',n_jobs=-1,random_state=25)

from sklearn.ensemble import StackingClassifier
clf=StackingClassifier(estimators=est0,final_estimator=est_final,n_jobs=-1)
clf.fit(x_train_encode,y_train)

y_train_pred=clf.predict(x_train_encode)
y_test_pred=clf.predict(x_test_encode)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'stack.png')

"""### **9.VotingClassifier**


"""

est0=list()
est0.append(('lr',SGDClassifier(loss='log',alpha=0.1,random_state=25,n_jobs=-1)))
est0.append(('dt',DecisionTreeClassifier(max_depth=135,min_samples_leaf=28,min_samples_split=193,random_state=25)))
est0.append(('rf',RandomForestClassifier(max_depth=13,min_samples_leaf=49,min_samples_split=165,n_estimators=108,random_state=25,n_jobs=-1)))
est0.append(('xgb',XGBClassifier(n_estimators=123,max_depth=3,subsample=1,learning_rate=0.1,colsample_bytree=1,random_state=25,n_jobs=-1)))

from sklearn.ensemble import VotingClassifier
vot_hard=VotingClassifier(estimators=est0,voting='hard')
vot_hard.fit(x_train_encode,y_train)

y_train_pred=vot_hard.predict(x_train_encode)
y_test_pred=vot_hard.predict(x_test_encode)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'votclf_1.png')

# Voting Classifier with soft voting

vot_soft=VotingClassifier(estimators=est0,voting='soft')
vot_soft.fit(x_train_encode,y_train)

y_train_pred=vot_soft.predict(x_train_encode)
y_test_pred=vot_soft.predict(x_test_encode)

print('Train f1 score:',f1_score(y_train,y_train_pred,average='macro'))
print('Test f1 score:',f1_score(y_test,y_test_pred,average='macro'))

confusion_metrices_plot(y_train,y_train_pred,y_test,y_test_pred,'votclf_2.png')

"""***Summary***"""

from prettytable import PrettyTable 
x = PrettyTable()
x.field_names = ["Model", "Hyper parameter", "test f1-Score"]
x.add_row(['logistic ','alpha=10','0.63545'])
x.add_row(['Regression',' ',' '])
x.add_row([' ',' ',' '])
x.add_row(['Linear SVM','alpha=10','0.699314'])
x.add_row([' ',' ',' '])
x.add_row(['Decision Tree','max_depth=135','0.66602'])
x.add_row([' ','min_samples_leaf= 28,min_samples_split=193',' '])
x.add_row([' ',' ',' '])
x.add_row(['Random Forest','max_depth =13, min_samples_leaf=49','0.681056'])
x.add_row([' ','min_samples_split =165,n_estimators=108',' '])
x.add_row([' ',' ',' '])
x.add_row(['XGBclassifier','n_estimators=120, max_depth=3','0.69298'])
x.add_row([' ','subsample=0.5,learning_rate=0.1,colsample_bytree=1',' '])
x.add_row([' ',' ',' '])
x.add_row(['LGBMClassifier','n_estimators=250, max_depth=3','0.68229'])
x.add_row([' ','subsample=0.5,learning_rate=0.03,colsample_bytree=0.3',' '])
x.add_row([' ',' ',' '])
x.add_row(['AdaBoost','n_estimators=1, learning_rate=0.001','0.68584'])
x.add_row([' ',' ',' '])
x.add_row(['StackingClassifier','estimators=est0, final_estimator = est_final','0.66506'])
x.add_row([' ',' ',' '])
x.add_row(['VotingClassifier',' ',' '])
x.add_row(['vot_hard','estimators = est0, voting =hard','0.68045'])
x.add_row(['vot_soft','estimators = est0, voting = soft','0.66974'])
x.add_row([' ',' ',' '])
print(x)



